//apps/api/src/agents/topicDiscovery.ts
import { prisma } from "db";
import { TopicStatus, ContentType } from "db";
import { fetchGoogleTrends } from "../lib/trends/googleTrends.js";
import { groupTitlesWithGemini, SourceInput, embedText } from "../lib/gemini.js";
import { slugify } from "../lib/slugify.js";
import { normalizeUrl, sha1 } from "../../../../packages/core/src/utils/url.js"; // keep .js
import { searchTopicVector, upsertTopicVector, ensureTopicCollection } from "../lib/qdrant.js";
import { randomUUID } from "crypto";
/**
 * Normalize incoming contentType values to match Prisma enum
 */
function normalizeContentType(val?: string | null): ContentType | null {
  if (!val) return null;
  const upper = val.toUpperCase();

  // Map common variations
  if (upper === "HOW-TO") return ContentType.HOWTO;

  // Pass through valid enum values
  if ((Object.values(ContentType) as string[]).includes(upper)) {
    return upper as ContentType;
  }

  // Fallback: drop invalids
  return null;
}

/**
 * Run full discovery pipeline:
 * 1) Fetch Google Trends
 * 2) Gemini groups + filters to tech topics
 * 3) Save topics + sources in DB (skip Qdrant for now)
 */
export async function runTopicDiscovery() {
  await ensureTopicCollection();
  console.log("üöÄ Starting topic discovery‚Ä¶");

  // 1) Fetch raw trends
  const items: SourceInput[] = await fetchGoogleTrends();
  console.log(`üì∞  Fetched ${items.length} items from Google Trends.`);

  // --- PRE-GEMINI URL DEDUP ---
  const itemsForGrouping: SourceInput[] = [];
  let skippedDuplicates = 0;

  for (const it of items) {
    if (!it?.url) continue;
    const urlNorm = normalizeUrl(it.url);
    const urlHash = sha1(urlNorm);

    // If you added @unique on Source.urlHash, you can use findUnique here.
    const exists = await prisma.source.findFirst({ where: { urlHash } });

    if (!exists) {
      itemsForGrouping.push({ ...it, urlNorm, urlHash } as any);
    } else {
      skippedDuplicates++;
      // üëá exact message for titles eliminated as already present
      console.log(`‚ö™ Skipped duplicate source: "${it.title}" (${it.url})`);
    }
  }

  if (!itemsForGrouping.length) {
    console.warn("‚úÖ No new URLs after deduplication.");
    console.log(`‚ÑπÔ∏è Summary: fetched=${items.length}, skippedDuplicates=${skippedDuplicates}, toGroup=0`);
    return [];
  }
  console.log(`üß© ${itemsForGrouping.length} unique items will be grouped (skipped ${skippedDuplicates}).`);
  // --- END PRE-GEMINI URL DEDUP ---

  if (!items.length) {
    console.warn("‚ö†Ô∏è No items fetched from Google Trends.");
    return [];
  }

  // 2) Group with Gemini (filters non-tech internally)
  let grouped: { topics?: Array<{ master: string; children?: SourceInput[] }> } | undefined;
  let errorMessage: string | null = null;

try {
  grouped = await groupTitlesWithGemini(itemsForGrouping);
} catch (err: any) {
  console.error("‚ùå Gemini grouping failed:", err);
  errorMessage = err.message || "Gemini grouping failed";
}

if (!grouped?.topics?.length) {
  console.warn("‚ö†Ô∏è Gemini returned no topics after filtering.");
  errorMessage = errorMessage || "Gemini returned empty grouping";
  // üëá ensure we still define an empty list to prevent TS undefined issues
  grouped = { topics: [] };
} else {
  console.log(`üß† Gemini produced ${grouped.topics.length} topic groups.`);
}

const createdTopics: any[] = [];
let reusedCount = 0;
let createdCount = 0;

// ‚úÖ Safe loop: TypeScript knows grouped.topics is always defined now
const safeTopics = grouped?.topics ?? [];
for (const group of safeTopics) {
    const master = group.master?.trim();
    if (!master) continue;

    const topicSlug = slugify(master);
    console.log(`\nüîç Processing master topic: "${master}"`);

    // 2.5) Try semantic reuse via Qdrant (‚â• 0.85)
    let topic: any = null;

    try {
      // 1) embed master title
      const vector = await embedText(master);

      // 2) ask Qdrant for nearest topic match (returns ScoredPoint[])
      const hits = await searchTopicVector(vector, 3, 0.75);
      if (hits.length) {
        const best = hits[0];
        const payload: any = best.payload || {};
        const reuseId = typeof best.id === "string" ? best.id : undefined;
        const reuseSlug = payload?.slug || (payload?.title ? slugify(payload.title) : undefined);

        // Prefer ID (we'll upsert with topic.id as the point id), else fallback to slug
        if (reuseId) {
          topic = await prisma.topic.findUnique({ where: { id: reuseId }, include: { sources: true } });
        } else if (reuseSlug) {
          topic = await prisma.topic.findUnique({ where: { slug: reuseSlug }, include: { sources: true } });
        }

        if (topic) {
          reusedCount++;
          console.log(`üîÅ Reused existing topic ‚Üí "${topic.title}" (id: ${topic.id})`);
          // refresh vector + optional fields
          await upsertTopicVector(randomUUID(), vector,{ title: master, slug: topic.slug, dbId: topic.id });

          await prisma.topic.update({
            where: { id: topic.id },
            data: {
              // lastSeenAt: new Date(),
              // titleEmbedding: vector as any,
            },
          });
        }
      }

      // 3) If no reusable topic, fall back to your original slug flow
      if (!topic) {
        topic = await prisma.topic.findUnique({
          where: { slug: topicSlug },
          include: { sources: true },
        });

        if (!topic) {
          topic = await prisma.topic.create({
            data: {
              title: master,
              slug: topicSlug,
              status: TopicStatus.NEW,
              // titleEmbedding: vector as any, // uncomment if you've added this field
            },
            include: { sources: true },
          });

          // 4) Index the new topic in Qdrant with Postgres topic.id as the point id
          //    This makes future reuse by ID trivial.
          await upsertTopicVector(
  randomUUID(),
  vector,
  { title: master, slug: topic.slug, dbId: topic.id }
);

          createdCount++;
          // üëá exact message for newly inserted topic
          console.log(`üÜï Created NEW topic ‚Üí "${master}" (slug: ${topic.slug}, id: ${topic.id})`);
          await prisma.auditLog.create({
  data: {
    action: "TOPIC_CREATED",
    topicId: topic.id,
    meta: {
      title: topic.title,
      sources: topic.sources?.length || 0,
      status: topic.status,
      reused: false,
    },
  },
});

        } else {
          // If found by slug only (without Qdrant), still useful to log
          reusedCount++;
          console.log(`üîÅ Reused existing topic by slug ‚Üí "${topic.title}" (id: ${topic.id})`);
          await prisma.auditLog.create({
  data: {
    action: "TOPIC_REUSED",
    topicId: topic.id,
    meta: {
      title: topic.title,
      sources: topic.sources?.length || 0,
      status: topic.status,
      reused: true,
    },
  },
});

        }
      }
    } catch (err) {
      console.error("‚ö†Ô∏è Qdrant/Gemini embedding lookup failed, falling back to slug:", err);

      // Original fallback (no embeddings)
      const topicSlugFallback = slugify(master);
      topic = await prisma.topic.findUnique({
        where: { slug: topicSlugFallback },
        include: { sources: true },
      });

      if (!topic) {
        topic = await prisma.topic.create({
          data: {
            title: master,
            slug: topicSlugFallback,
            status: TopicStatus.NEW,
          },
          include: { sources: true },
        });
        createdCount++;
        console.log(`üÜï Created NEW topic (fallback) ‚Üí "${master}" (slug: ${topic.slug}, id: ${topic.id})`);
      } else {
        reusedCount++;
        console.log(`üîÅ Reused existing topic (fallback) ‚Üí "${topic.title}" (id: ${topic.id})`);
      }
    }

    // Deduplicate & insert sources
    const existingUrls = new Set(topic.sources.map((s: { url: string }) => s.url));
    const newSources: SourceInput[] = (group.children || []).filter(
      (c: SourceInput) => c?.title && c?.url && !existingUrls.has(c.url)
    );

    if (newSources.length) {
      await prisma.source.createMany({
        data: newSources.map((s: any) => {
          const urlNorm = normalizeUrl(s.url);
          const urlHash = sha1(urlNorm);
          return {
            url: s.url,
            urlNorm,
            urlHash,
            title: s.title,
            kind: s.kind,
            contentType: normalizeContentType(s.contentType),
            approved: false,
            topicId: topic!.id,
          };
        }),
        skipDuplicates: true,
      });

      console.log(`ü™∂ Added ${newSources.length} new sources under "${topic.title}"`);
    } else {
      console.log(`‚ö™ No new sources for "${topic.title}"`);
    }

    if (topic) {
      console.log(`üìå Saved topic: ${topic.title} (${topic.sources.length} sources total pre-insert)`); // note: count before refresh
      // optional: refresh topic.sources count from DB if you want the latest number here
      const refreshed = await prisma.topic.findUnique({
        where: { id: topic.id },
        include: { sources: true },
      });
      if (refreshed) {
        console.log(`üìå Post-insert sources count: ${refreshed.sources.length}`);
        createdTopics.push(refreshed);
      } else {
        createdTopics.push(topic);
      }
    }
  }
// === Log pipeline summary to AuditLog ===
const summary = {
  timestamp: new Date().toISOString(),
  fetchedCount: items.length,
  skippedDuplicates,
  groupedCount: grouped?.topics?.length || 0,
  topicsCreated: createdCount,
  topicsReused: reusedCount,
  sourcesFetched: itemsForGrouping.length,
  topicsProcessed: createdTopics.length,
  error: errorMessage, // ‚úÖ FIX 1 ‚Äî added missing comma before this line
};

try {
  await prisma.auditLog.create({
    data: { action: "TOPIC_DISCOVERY_RUN", meta: summary },
  });
  console.log("üßæ Discovery summary logged to AuditLog:", summary);
} catch (err) {
  console.error("‚ùå Failed to write AuditLog entry:", err);
}

// ‚úÖ FIX 2 ‚Äî safer summary console showing error field for debugging
console.log(
  `\n‚úÖ Discovery completed. topicsProcessed=${createdTopics.length}, topicsCreated=${createdCount}, topicsReused=${reusedCount}, sourcesFetched=${items.length}, sourcesSkipped=${items.length - itemsForGrouping.length}, error=${errorMessage || "none"}`
);

return createdTopics.filter((t) => t?.status === TopicStatus.NEW);

}
